{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Retrieval Model Ver 2 (Multitask recommender).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vfabl-zJjVaw",
        "kKgt18nRZgRQ",
        "g4bwyBnikR0s",
        "1NxltrVLVPR_",
        "cDnTAKradwOP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORT"
      ],
      "metadata": {
        "id": "vfabl-zJjVaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ],
      "metadata": {
        "id": "MZJcWjNgjcJ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3ee58c-59fb-4b99-abb9-6ddd8ab236a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 42.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymysql\n",
        "!pip install ipython-sql\n",
        "!pip install mysqlclient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jn-1wBi8Pv2",
        "outputId": "4d265a7e-e7f4-4313-9814-8f44070fa97f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython-sql in /usr/local/lib/python3.7/dist-packages (0.3.9)\n",
            "Requirement already satisfied: ipython>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipython-sql) (5.5.0)\n",
            "Requirement already satisfied: sqlalchemy>=0.6.7 in /usr/local/lib/python3.7/dist-packages (from ipython-sql) (1.4.36)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from ipython-sql) (1.15.0)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from ipython-sql) (3.3.0)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.7/dist-packages (from ipython-sql) (0.4.2)\n",
            "Requirement already satisfied: ipython-genutils>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipython-sql) (0.2.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=1.0->ipython-sql) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=1.0->ipython-sql) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=1.0->ipython-sql) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=1.0->ipython-sql) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=1.0->ipython-sql) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=1.0->ipython-sql) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=1.0->ipython-sql) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=1.0->ipython-sql) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=1.0->ipython-sql) (0.2.5)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=0.6.7->ipython-sql) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=0.6.7->ipython-sql) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=0.6.7->ipython-sql) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=0.6.7->ipython-sql) (3.8.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=1.0->ipython-sql) (0.7.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.1.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 2.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mysqlclient\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.1.0-cp37-cp37m-linux_x86_64.whl size=99966 sha256=5f476733d5a2285feb60e53fb6e3f57fe45d0c665b160518494018ddacfd7730\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/d4/df/08cd6e1fa4a8691b268ab254bd0fa589827ab5b65638c010b4\n",
            "Successfully built mysqlclient\n",
            "Installing collected packages: mysqlclient\n",
            "Successfully installed mysqlclient-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "# getting data\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "zc0yadWJjXf1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/Othercomputers/My Laptop/Bangkit/Capstone/Recommender system/Notogo-ML/model_v2.0 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w53xOMLQkuvE",
        "outputId": "3f465c36-3f88-44bc-bd51-ac110a2e62df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Othercomputers/My Laptop/Bangkit/Capstone/Recommender system/Notogo-ML/model_v2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylsxRIzFk4h8",
        "outputId": "3934a238-3ca4-403a-b483-6c2629c7a82f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Othercomputers/My Laptop/Bangkit/Capstone/Recommender system/Notogo-ML/model_v2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOAD DATA FROM MYSQL"
      ],
      "metadata": {
        "id": "kKgt18nRZgRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "import pymysql\n",
        "import pandas as pd\n",
        "\n",
        "# db_connection = 'mysql+pymysql://root:@localhost/notogo_database'\n",
        "# conn = create_engine(db_connection)\n",
        "\n",
        "# df = pd.read_sql(\"select * from tab_name\", conn)\n",
        "\n",
        "db_connect =pymysql.connect(host='127.0.0.1',user='root',password='',db='notogo_database')\n",
        "\n",
        "# df=pd.read_sql_query(\"SELECT * FROM 'YOUR_TABLENAME' \",conn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "7mpZbWjjaFvR",
        "outputId": "d74f1b20-821f-4d74-ad11-d3bd51e9069b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OperationalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    613\u001b[0m                             sock = socket.create_connection(\n\u001b[0;32m--> 614\u001b[0;31m                                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m                             )\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    715\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-df9c8f0f8169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# df = pd.read_sql(\"select * from tab_name\", conn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdb_connect\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpymysql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'127.0.0.1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'root'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'notogo_database'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# df=pd.read_sql_query(\"SELECT * FROM 'YOUR_TABLENAME' \",conn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymysql/connections.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, user, password, host, database, unix_socket, port, charset, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pymysql/connections.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self, sock)\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;31m# If e is neither DatabaseError or IOError, It's a bug.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: (2003, \"Can't connect to MySQL server on '127.0.0.1' ([Errno 111] Connection refused)\")"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -y install mysql-server"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgmzeeDUkPOM",
        "outputId": "464492b2-60f9-4d91-a844-9e932bcd7364"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libcgi-fast-perl libcgi-pm-perl libencode-locale-perl libevent-core-2.1-6\n",
            "  libfcgi-perl libhtml-parser-perl libhtml-tagset-perl libhtml-template-perl\n",
            "  libhttp-date-perl libhttp-message-perl libio-html-perl\n",
            "  liblwp-mediatypes-perl libtimedate-perl liburi-perl mysql-client-5.7\n",
            "  mysql-client-core-5.7 mysql-server-5.7 mysql-server-core-5.7\n",
            "Suggested packages:\n",
            "  libdata-dump-perl libipc-sharedcache-perl libwww-perl mailx tinyca\n",
            "The following NEW packages will be installed:\n",
            "  libcgi-fast-perl libcgi-pm-perl libencode-locale-perl libevent-core-2.1-6\n",
            "  libfcgi-perl libhtml-parser-perl libhtml-tagset-perl libhtml-template-perl\n",
            "  libhttp-date-perl libhttp-message-perl libio-html-perl\n",
            "  liblwp-mediatypes-perl libtimedate-perl liburi-perl mysql-client-5.7\n",
            "  mysql-client-core-5.7 mysql-server mysql-server-5.7 mysql-server-core-5.7\n",
            "0 upgraded, 19 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 19.6 MB of archives.\n",
            "After this operation, 155 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 mysql-client-core-5.7 amd64 5.7.38-0ubuntu0.18.04.1 [6,632 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 mysql-client-5.7 amd64 5.7.38-0ubuntu0.18.04.1 [1,942 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 mysql-server-core-5.7 amd64 5.7.38-0ubuntu0.18.04.1 [7,424 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libevent-core-2.1-6 amd64 2.1.8-stable-4build1 [85.9 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 mysql-server-5.7 amd64 5.7.38-0ubuntu0.18.04.1 [2,905 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-template-perl all 2.97-1 [59.0 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 mysql-server all 5.7.38-0ubuntu0.18.04.1 [9,952 B]\n",
            "Fetched 19.6 MB in 2s (12.0 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package mysql-client-core-5.7.\n",
            "(Reading database ... 155629 files and directories currently installed.)\n",
            "Preparing to unpack .../00-mysql-client-core-5.7_5.7.38-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking mysql-client-core-5.7 (5.7.38-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package mysql-client-5.7.\n",
            "Preparing to unpack .../01-mysql-client-5.7_5.7.38-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking mysql-client-5.7 (5.7.38-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package mysql-server-core-5.7.\n",
            "Preparing to unpack .../02-mysql-server-core-5.7_5.7.38-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking mysql-server-core-5.7 (5.7.38-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libevent-core-2.1-6:amd64.\n",
            "Preparing to unpack .../03-libevent-core-2.1-6_2.1.8-stable-4build1_amd64.deb ...\n",
            "Unpacking libevent-core-2.1-6:amd64 (2.1.8-stable-4build1) ...\n",
            "Selecting previously unselected package mysql-server-5.7.\n",
            "Preparing to unpack .../04-mysql-server-5.7_5.7.38-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking mysql-server-5.7 (5.7.38-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-3) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n",
            "Unpacking liburi-perl (1.73-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl.\n",
            "Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl (3.72-3build1) ...\n",
            "Selecting previously unselected package libcgi-pm-perl.\n",
            "Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n",
            "Unpacking libcgi-pm-perl (4.38-1) ...\n",
            "Selecting previously unselected package libfcgi-perl.\n",
            "Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n",
            "Unpacking libfcgi-perl (0.78-2build1) ...\n",
            "Selecting previously unselected package libcgi-fast-perl.\n",
            "Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n",
            "Unpacking libcgi-fast-perl (1:2.13-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../11-libencode-locale-perl_1.05-1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1) ...\n",
            "Selecting previously unselected package libhtml-template-perl.\n",
            "Preparing to unpack .../12-libhtml-template-perl_2.97-1_all.deb ...\n",
            "Unpacking libhtml-template-perl (2.97-1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../13-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../14-libhttp-date-perl_6.02-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.02-1) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../15-libio-html-perl_1.001-1_all.deb ...\n",
            "Unpacking libio-html-perl (1.001-1) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../16-liblwp-mediatypes-perl_6.02-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.02-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../17-libhttp-message-perl_6.14-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.14-1) ...\n",
            "Selecting previously unselected package mysql-server.\n",
            "Preparing to unpack .../18-mysql-server_5.7.38-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking mysql-server (5.7.38-0ubuntu0.18.04.1) ...\n",
            "Setting up libhtml-tagset-perl (3.20-3) ...\n",
            "Setting up libevent-core-2.1-6:amd64 (2.1.8-stable-4build1) ...\n",
            "Setting up libencode-locale-perl (1.05-1) ...\n",
            "Setting up mysql-server-core-5.7 (5.7.38-0ubuntu0.18.04.1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libio-html-perl (1.001-1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.02-1) ...\n",
            "Setting up liburi-perl (1.73-1) ...\n",
            "Setting up libhtml-parser-perl (3.72-3build1) ...\n",
            "Setting up libcgi-pm-perl (4.38-1) ...\n",
            "Setting up mysql-client-core-5.7 (5.7.38-0ubuntu0.18.04.1) ...\n",
            "Setting up libfcgi-perl (0.78-2build1) ...\n",
            "Setting up libhttp-date-perl (6.02-1) ...\n",
            "Setting up libhtml-template-perl (2.97-1) ...\n",
            "Setting up libcgi-fast-perl (1:2.13-1) ...\n",
            "Setting up libhttp-message-perl (6.14-1) ...\n",
            "Setting up mysql-client-5.7 (5.7.38-0ubuntu0.18.04.1) ...\n",
            "Setting up mysql-server-5.7 (5.7.38-0ubuntu0.18.04.1) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of stop.\n",
            "update-alternatives: using /etc/mysql/mysql.cnf to provide /etc/mysql/my.cnf (my.cnf) in auto mode\n",
            "Renaming removed key_buffer and myisam-recover options (if present)\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/mysql.service → /lib/systemd/system/mysql.service.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up mysql-server (5.7.38-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for systemd (237-3ubuntu10.53) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_connect = sql.connect(host = '127.0.0.1', database = 'notogo_database', user = 'root', password = '')"
      ],
      "metadata": {
        "id": "gpz0SbfKZjzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.experimental.SqlDataset(\"mysql\", \"/foo/bar.sqlite3\",\n",
        "                                          \"SELECT name, age FROM people\",\n",
        "                                          (tf.string, tf.int32))"
      ],
      "metadata": {
        "id": "uogFcdeadywS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the dataset"
      ],
      "metadata": {
        "id": "g4bwyBnikR0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import userFeatures\n",
        "builder = tfds.builder('Userfeatures')\n",
        "userFeatureDs = tfds.load('Userfeatures',split='train')"
      ],
      "metadata": {
        "id": "rY9WTfBdm7RS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wishEmbedding\n",
        "builder = tfds.builder('Wishembedding')\n",
        "wishEmbeddingDs = tfds.load('Wishembedding',split='train')"
      ],
      "metadata": {
        "id": "KE_CXF__nPmg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = userFeatureDs.map(lambda x: {\n",
        "    \"location_name\": x[\"location_name\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"add\" : x[\"add\"],\n",
        "    \"like\" : x[\"like\"]\n",
        "})\n",
        "locations = wishEmbeddingDs.map(lambda x: x[\"location_name\"])"
      ],
      "metadata": {
        "id": "huWx0o8PnUGg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in ratings.take(2).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9I0OIcQ33NY",
        "outputId": "ccb0ed84-dd8c-44ab-f84e-d30df1f9cd8c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'add': 0, 'like': 1, 'location_name': b'JAKARTA', 'user_id': b'93'}\n",
            "{'add': 0, 'like': 1, 'location_name': b'DUBAI', 'user_id': b'112'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "NUM_DATA = ratings.__len__().numpy()\n",
        "\n",
        "shuffled = ratings.shuffle(NUM_DATA, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "trainset_size = 0.8 * NUM_DATA\n",
        "\n",
        "train = shuffled.take(trainset_size)\n",
        "test = shuffled.skip(trainset_size).take(NUM_DATA - trainset_size)\n",
        "\n",
        "location_name = locations.batch(1000)\n",
        "user_ids = ratings.batch(1000).map(lambda x: x[\"user_id\"])\n",
        "\n",
        "unique_location_name = np.unique(np.concatenate(list(location_name)))\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
      ],
      "metadata": {
        "id": "fwnbwMsGrgJP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL"
      ],
      "metadata": {
        "id": "VpzmeDIltZuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two critical parts to multi-task recommenders:\n",
        "\n",
        "1. They optimize for two or more objectives, and so have two or more losses.\n",
        "2. They share variables between the tasks, allowing for transfer learning."
      ],
      "metadata": {
        "id": "7-ZYWHH7thiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class NoToGoModel(tfrs.models.Model):\n",
        "\n",
        "#   def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
        "#     # We take the loss weights in the constructor: this allows us to instantiate\n",
        "#     # several model objects with different loss weights.\n",
        "\n",
        "#     super().__init__()\n",
        "\n",
        "#     embedding_dimension = 32\n",
        "\n",
        "#     # User and movie models.\n",
        "#     self.location_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
        "#       tf.keras.layers.StringLookup(\n",
        "#         vocabulary=unique_location_name, mask_token=None),\n",
        "#       tf.keras.layers.Embedding(len(unique_location_name) + 1, embedding_dimension),\n",
        "#       tf.keras.layers.Dense(32, activation=\"relu\")\n",
        "#     ])\n",
        "#     self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
        "#       tf.keras.layers.StringLookup(\n",
        "#         vocabulary=unique_user_ids, mask_token=None),\n",
        "#       tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension),\n",
        "#       tf.keras.layers.Dense(32, activation=\"relu\")\n",
        "#     ])\n",
        "\n",
        "#     # A small model to take in user and movie embeddings and predict ratings.\n",
        "#     # We can make this as complicated as we want as long as we output a scalar\n",
        "#     # as our prediction.\n",
        "#     self.rating_model = tf.keras.Sequential([\n",
        "#         tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "#         tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "#         tf.keras.layers.Dense(1, activation = \"sigmoid\"),\n",
        "#     ])\n",
        "\n",
        "#     # The tasks.\n",
        "#     self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "#         loss=tf.keras.losses.MeanSquaredError(),\n",
        "#         metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
        "#     )\n",
        "#     self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "#         metrics=tfrs.metrics.FactorizedTopK(\n",
        "#             candidates=locations.batch(128).map(self.location_model)\n",
        "#         )\n",
        "#     )\n",
        "\n",
        "#     # The loss weights.\n",
        "#     self.rating_weight = rating_weight\n",
        "#     self.retrieval_weight = retrieval_weight\n",
        "\n",
        "#   def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "#     # We pick out the user features and pass them into the user model.\n",
        "#     user_embeddings = self.user_model(features[\"user_id\"])\n",
        "#     # And pick out the movie features and pass them into the movie model.\n",
        "#     location_embeddings = self.location_model(features[\"location_name\"])\n",
        "    \n",
        "#     return (\n",
        "#         user_embeddings,\n",
        "#         location_embeddings,\n",
        "#         # We apply the multi-layered rating model to a concatentation of\n",
        "#         # user and movie embeddings.\n",
        "#         self.rating_model(\n",
        "#             tf.concat([user_embeddings,location_embeddings], axis=1)\n",
        "#         ),\n",
        "#     )\n",
        "\n",
        "#   def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "\n",
        "#     ratings = features.pop(\"add\")\n",
        "\n",
        "#     user_embeddings, location_embeddings, rating_predictions = self(features)\n",
        "\n",
        "#     # We compute the loss for each task.\n",
        "#     rating_loss = self.rating_task(\n",
        "#         labels=ratings,\n",
        "#         predictions=rating_predictions,\n",
        "#     )\n",
        "#     retrieval_loss = self.retrieval_task(user_embeddings, location_embeddings)\n",
        "\n",
        "#     # And combine them using the loss weights.\n",
        "#     return (self.rating_weight * rating_loss\n",
        "#             + self.retrieval_weight * retrieval_loss)"
      ],
      "metadata": {
        "id": "SWJfk6gdtyvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoToGoModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, rating_weight: float, like_weight: float,retrieval_weight: float) -> None:\n",
        "    # We take the loss weights in the constructor: this allows us to instantiate\n",
        "    # several model objects with different loss weights.\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    embedding_dimension = 32\n",
        "\n",
        "    # User and movie models.\n",
        "    self.location_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_location_name, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_location_name) + 1, embedding_dimension),\n",
        "      tf.keras.layers.Dense(16, activation=\"relu\")\n",
        "    ])\n",
        "\n",
        "    self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_user_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension),\n",
        "      tf.keras.layers.Dense(16, activation=\"relu\")\n",
        "    ])\n",
        "\n",
        "    # A small model to take in user and movie embeddings and predict ratings.\n",
        "    # We can make this as complicated as we want as long as we output a scalar\n",
        "    # as our prediction.\n",
        "    self.rating_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(8, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(1, activation = \"sigmoid\"),\n",
        "    ])\n",
        "\n",
        "    self.like_model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(1, activation = \"sigmoid\"),\n",
        "    ])\n",
        "\n",
        "    # The tasks.\n",
        "    self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "        loss=tf.keras.losses.MeanSquaredError(),\n",
        "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
        "    )\n",
        "\n",
        "    self.like_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "        loss=tf.keras.losses.MeanSquaredError(),\n",
        "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
        "    )\n",
        "    self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=locations.batch(128).map(self.location_model)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # The loss weights.\n",
        "    self.rating_weight = rating_weight\n",
        "    self.retrieval_weight = retrieval_weight\n",
        "    self.like_weight = like_weight\n",
        "\n",
        "  def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    user_embeddings = self.user_model(features[\"user_id\"])\n",
        "    # And pick out the movie features and pass them into the movie model.\n",
        "    location_embeddings = self.location_model(features[\"location_name\"])\n",
        "    \n",
        "    return (\n",
        "        user_embeddings,\n",
        "        location_embeddings,\n",
        "        # We apply the multi-layered rating model to a concatentation of\n",
        "        # user and movie embeddings.\n",
        "        self.rating_model(\n",
        "            tf.concat([user_embeddings,location_embeddings], axis=1)\n",
        "        ),\n",
        "        self.like_model(\n",
        "            tf.concat([user_embeddings,location_embeddings], axis=1)\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "\n",
        "    ratings = features.pop(\"add\",\"like\")\n",
        "    like = features.pop(\"like\", \"add\")\n",
        "\n",
        "    user_embeddings, location_embeddings, rating_predictions, like_predictions = self(features)\n",
        "\n",
        "    # We compute the loss for each task.\n",
        "    rating_loss = self.rating_task(\n",
        "        labels=ratings,\n",
        "        predictions=rating_predictions,\n",
        "    )\n",
        "\n",
        "    like_loss = self.like_task(\n",
        "        labels=like,\n",
        "        predictions=like_predictions,\n",
        "    )\n",
        "    retrieval_loss = self.retrieval_task(user_embeddings, location_embeddings)\n",
        "\n",
        "    # And combine them using the loss weights.\n",
        "    return (self.rating_weight * rating_loss\n",
        "            + self.retrieval_weight * retrieval_loss + like_loss*self.like_weight)"
      ],
      "metadata": {
        "id": "w2FZCFQdwrO6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SKIP"
      ],
      "metadata": {
        "id": "1NxltrVLVPR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testModel = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_location_name, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_location_name) + 1, 32),\n",
        "      tf.keras.layers.Dense(32, activation=\"relu\")\n",
        "])"
      ],
      "metadata": {
        "id": "-RV72MCPVQ-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cek = tf.keras.layers.StringLookup(vocabulary=unique_location_name, mask_token=None)"
      ],
      "metadata": {
        "id": "b4DWPnMvVyiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_location_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX32kdeyXi8k",
        "outputId": "b6920c79-dd42-45ad-d46f-3c6461322b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'AIR TERJUN SIPISO-PISO', b'AKIHABARA', b'ALASKA',\n",
              "       b'AMERIKA SERIKAT', b'ANCOL', b'ASIA TIMUR', b'BALI',\n",
              "       b'BALI TOWER', b'BANDUNG', b'BANGKA BELITUNG', b'BHUTAN',\n",
              "       b'BRANCHSTO BSD', b'CANDI BOROBUDUR', b'CANDI PRAMBANAN',\n",
              "       b'CANGGU', b'CAPADOCIA', b'DANAU SALAR DE UYUNI', b'DANAU TOBA',\n",
              "       b'DENMARK', b'DIENG', b'DISNEY SEA', b'DISNEYLAND PARIS', b'DUBAI',\n",
              "       b'DUFAN', b'EROPA', b'ES KRIM RAGUSA', b'EUROPE',\n",
              "       b'GAMPLONG STUDIO', b'GEOPARK CILETUH', b'GUA GONG',\n",
              "       b'GUA TABUHAN', b'GUMUK PASIR PARANGKUSUMO', b'GUNUNG',\n",
              "       b'GUNUNG AGUNG', b'GUNUNG BROMO', b'GUNUNG FUJI', b'GUNUNG GEDE',\n",
              "       b'GUNUNG PANGRANGO', b'GUNUNG PARANG', b'GUNUNG RINJANI',\n",
              "       b'GUNUNG SEMERU', b'INDONESIA', b'ISRAEL', b'JAKARTA',\n",
              "       b'JAWA BARAT', b'JEPANG', b'JERMAN', b'KATULAMPA RAFTING BOGOR',\n",
              "       b'KENDARI', b'KOREA SELATAN', b'LABUAN BAJO', b'LAMPUNG',\n",
              "       b'LOMBOK', b'LONDON', b'MALANG', b'MALAYSIA', b'MALDIVES',\n",
              "       b'MALIOBORO', b'MALL PAKUWON', b'MARINA BAY STREET CIRCUIT',\n",
              "       b'MEDAN', b'MEKKAH', b'MUSEUM ANGKUT', b'MUSEUM GEOLOGI BANDUNG',\n",
              "       b'MUSEUM GHIBLI', b'MUSEUM IPTEK', b'MUSEUM LOUVRE',\n",
              "       b'MUSEUM MACAN', b'MUSEUM MOJA', b'MUSEUM NASIONAL',\n",
              "       b'MUSEUM NASIONAL IMERSIFA', b'NEW YORK', b'NEW ZEALAND',\n",
              "       b'NUSA DUA', b'NUSA PENIDA', b'NUSA TENGGARA BARAT',\n",
              "       b'NUSAWIRU PARACENTER', b'PALEMBANG', b'PANGANDARAN',\n",
              "       b'PANTAI ANCOL', b'PANTAI KLAYAR', b'PANTAI KUTA',\n",
              "       b'PANTAI SELATAN', b'PANTAI TELENGRIA', b'PANTAI WATU KARUNG',\n",
              "       b'PEMANDIAN AIR PANAS CIATER', b'PERANCIS', b'PERPUSNAS',\n",
              "       b'PONOROGO', b'PRANCIS', b'PULAU KOMODO', b'PULAU PAHAWANG',\n",
              "       b'PULAU SERIBU', b'RAJA AMPAT', b'REYKJAVIK', b'SINGAPURA',\n",
              "       b'SLOVENIA', b'SOLO', b'SUDIRMAN STREET BANDUNG', b'SUMBAR',\n",
              "       b'SURABAYA', b'SWISS', b'SWITZERLAND', b'TAMAN MEKARSARI',\n",
              "       b'TAMAN STRAWBERRY KADUDAMPIT', b'TANGERANG', b'TAPANULI TENGAH',\n",
              "       b'TAWANGMANGU', b'TEBING CITATAH', b'TEGAL', b'THAILAND', b'TOKYO',\n",
              "       b'TOKYO ', b'UJUNG KULON', b'UNIVERSAL STUDIO SINGAPORE',\n",
              "       b'WAKATOBI', b'WALT DISNEY WORLD FLORIDA', b'WATERBOM BALI',\n",
              "       b'YERUSALEM', b'YOGYAKARTA'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cek(tf.constant([['GUNUNG BROMO','DANAU TOBA']])) # 0 means out of vocabulary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1mmjGcCWKIF",
        "outputId": "3194dd36-a476-40e4-d64d-2b97bc73468a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[35, 18]])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rating-specialized model\n",
        "\n",
        "Depending on the weights we assign, the model will encode a different balance of the tasks. Let's start with a model that only considers ratings."
      ],
      "metadata": {
        "id": "2ML-UKVYYMc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NoToGoModel(rating_weight=1.0,like_weight = 0,retrieval_weight=0.0)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "QGP_6PjqYNxV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cached_train = train.shuffle(NUM_DATA).batch(512).cache()\n",
        "cached_test = test.batch(256).cache()"
      ],
      "metadata": {
        "id": "0srnK1mcYXgx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(cached_train, epochs=3)\n",
        "metrics = model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
        "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyI_1blbYomX",
        "outputId": "43f4f2cd-7b7d-4a25-e878-3683a86f7ff5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "43/43 [==============================] - 5s 80ms/step - root_mean_squared_error: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0315 - factorized_top_k/top_10_categorical_accuracy: 0.0714 - factorized_top_k/top_50_categorical_accuracy: 0.3940 - factorized_top_k/top_100_categorical_accuracy: 0.8136 - loss: 0.2093 - regularization_loss: 0.0000e+00 - total_loss: 0.2093\n",
            "Epoch 2/3\n",
            "43/43 [==============================] - 3s 80ms/step - root_mean_squared_error: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0027 - factorized_top_k/top_5_categorical_accuracy: 0.0353 - factorized_top_k/top_10_categorical_accuracy: 0.0758 - factorized_top_k/top_50_categorical_accuracy: 0.3992 - factorized_top_k/top_100_categorical_accuracy: 0.8233 - loss: 0.2001 - regularization_loss: 0.0000e+00 - total_loss: 0.2001\n",
            "Epoch 3/3\n",
            "43/43 [==============================] - 3s 81ms/step - root_mean_squared_error: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0362 - factorized_top_k/top_10_categorical_accuracy: 0.0755 - factorized_top_k/top_50_categorical_accuracy: 0.4012 - factorized_top_k/top_100_categorical_accuracy: 0.8242 - loss: 0.1999 - regularization_loss: 0.0000e+00 - total_loss: 0.1999\n",
            "22/22 [==============================] - 2s 73ms/step - root_mean_squared_error: 0.0000e+00 - factorized_top_k/top_1_categorical_accuracy: 0.0058 - factorized_top_k/top_5_categorical_accuracy: 0.0377 - factorized_top_k/top_10_categorical_accuracy: 0.0739 - factorized_top_k/top_50_categorical_accuracy: 0.4001 - factorized_top_k/top_100_categorical_accuracy: 0.8261 - loss: 0.1983 - regularization_loss: 0.0000e+00 - total_loss: 0.1983\n",
            "Retrieval top-100 accuracy: 0.826.\n",
            "Ranking RMSE: 0.000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieval-specialized model\n",
        "\n",
        "Let's now try a model that focuses on retrieval only."
      ],
      "metadata": {
        "id": "PPdD4CGJY76t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NoToGoModel(rating_weight=0.0, like_weight = 0, retrieval_weight=1.0)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "BfiJ8dCWY8PI"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(cached_train, epochs=10)\n",
        "metrics = model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
        "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dGpsHhDY-nK",
        "outputId": "1caf1b61-75cd-4fde-e31b-7e123bd9a075"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "43/43 [==============================] - 5s 86ms/step - root_mean_squared_error: 0.5035 - factorized_top_k/top_1_categorical_accuracy: 0.2187 - factorized_top_k/top_5_categorical_accuracy: 0.3649 - factorized_top_k/top_10_categorical_accuracy: 0.4474 - factorized_top_k/top_50_categorical_accuracy: 0.7308 - factorized_top_k/top_100_categorical_accuracy: 0.9200 - loss: 3180.4623 - regularization_loss: 0.0000e+00 - total_loss: 3180.4623\n",
            "Epoch 2/10\n",
            "43/43 [==============================] - 3s 81ms/step - root_mean_squared_error: 0.5035 - factorized_top_k/top_1_categorical_accuracy: 0.6530 - factorized_top_k/top_5_categorical_accuracy: 0.8466 - factorized_top_k/top_10_categorical_accuracy: 0.8855 - factorized_top_k/top_50_categorical_accuracy: 0.9807 - factorized_top_k/top_100_categorical_accuracy: 0.9993 - loss: 3180.2867 - regularization_loss: 0.0000e+00 - total_loss: 3180.2867\n",
            "Epoch 3/10\n",
            "43/43 [==============================] - 4s 85ms/step - root_mean_squared_error: 0.5036 - factorized_top_k/top_1_categorical_accuracy: 0.6943 - factorized_top_k/top_5_categorical_accuracy: 0.7603 - factorized_top_k/top_10_categorical_accuracy: 0.7837 - factorized_top_k/top_50_categorical_accuracy: 0.9250 - factorized_top_k/top_100_categorical_accuracy: 0.9910 - loss: 3180.2663 - regularization_loss: 0.0000e+00 - total_loss: 3180.2663\n",
            "Epoch 4/10\n",
            "43/43 [==============================] - 3s 79ms/step - root_mean_squared_error: 0.5054 - factorized_top_k/top_1_categorical_accuracy: 0.7369 - factorized_top_k/top_5_categorical_accuracy: 0.7970 - factorized_top_k/top_10_categorical_accuracy: 0.8243 - factorized_top_k/top_50_categorical_accuracy: 0.9550 - factorized_top_k/top_100_categorical_accuracy: 0.9912 - loss: 3180.1106 - regularization_loss: 0.0000e+00 - total_loss: 3180.1106\n",
            "Epoch 5/10\n",
            "43/43 [==============================] - 4s 86ms/step - root_mean_squared_error: 0.5061 - factorized_top_k/top_1_categorical_accuracy: 0.6901 - factorized_top_k/top_5_categorical_accuracy: 0.7549 - factorized_top_k/top_10_categorical_accuracy: 0.7932 - factorized_top_k/top_50_categorical_accuracy: 0.9719 - factorized_top_k/top_100_categorical_accuracy: 0.9918 - loss: 3179.9091 - regularization_loss: 0.0000e+00 - total_loss: 3179.9091\n",
            "Epoch 6/10\n",
            "43/43 [==============================] - 3s 77ms/step - root_mean_squared_error: 0.5063 - factorized_top_k/top_1_categorical_accuracy: 0.4205 - factorized_top_k/top_5_categorical_accuracy: 0.4612 - factorized_top_k/top_10_categorical_accuracy: 0.5044 - factorized_top_k/top_50_categorical_accuracy: 0.9084 - factorized_top_k/top_100_categorical_accuracy: 0.9891 - loss: 3179.9005 - regularization_loss: 0.0000e+00 - total_loss: 3179.9005\n",
            "Epoch 7/10\n",
            "43/43 [==============================] - 3s 79ms/step - root_mean_squared_error: 0.5066 - factorized_top_k/top_1_categorical_accuracy: 0.5310 - factorized_top_k/top_5_categorical_accuracy: 0.5874 - factorized_top_k/top_10_categorical_accuracy: 0.6515 - factorized_top_k/top_50_categorical_accuracy: 0.9258 - factorized_top_k/top_100_categorical_accuracy: 0.9868 - loss: 3179.6653 - regularization_loss: 0.0000e+00 - total_loss: 3179.6653\n",
            "Epoch 8/10\n",
            "43/43 [==============================] - 3s 78ms/step - root_mean_squared_error: 0.5085 - factorized_top_k/top_1_categorical_accuracy: 0.6005 - factorized_top_k/top_5_categorical_accuracy: 0.6422 - factorized_top_k/top_10_categorical_accuracy: 0.6779 - factorized_top_k/top_50_categorical_accuracy: 0.9306 - factorized_top_k/top_100_categorical_accuracy: 0.9896 - loss: 3179.4203 - regularization_loss: 0.0000e+00 - total_loss: 3179.4203\n",
            "Epoch 9/10\n",
            "43/43 [==============================] - 3s 77ms/step - root_mean_squared_error: 0.5103 - factorized_top_k/top_1_categorical_accuracy: 0.6033 - factorized_top_k/top_5_categorical_accuracy: 0.6738 - factorized_top_k/top_10_categorical_accuracy: 0.7084 - factorized_top_k/top_50_categorical_accuracy: 0.9306 - factorized_top_k/top_100_categorical_accuracy: 0.9946 - loss: 3179.2518 - regularization_loss: 0.0000e+00 - total_loss: 3179.2518\n",
            "Epoch 10/10\n",
            "43/43 [==============================] - 3s 78ms/step - root_mean_squared_error: 0.5105 - factorized_top_k/top_1_categorical_accuracy: 0.5666 - factorized_top_k/top_5_categorical_accuracy: 0.6733 - factorized_top_k/top_10_categorical_accuracy: 0.7032 - factorized_top_k/top_50_categorical_accuracy: 0.9383 - factorized_top_k/top_100_categorical_accuracy: 0.9952 - loss: 3179.1317 - regularization_loss: 0.0000e+00 - total_loss: 3179.1317\n",
            "22/22 [==============================] - 2s 69ms/step - root_mean_squared_error: 0.5108 - factorized_top_k/top_1_categorical_accuracy: 0.5855 - factorized_top_k/top_5_categorical_accuracy: 0.6765 - factorized_top_k/top_10_categorical_accuracy: 0.6852 - factorized_top_k/top_50_categorical_accuracy: 0.8700 - factorized_top_k/top_100_categorical_accuracy: 0.9984 - loss: 1347.4512 - regularization_loss: 0.0000e+00 - total_loss: 1347.4512\n",
            "Retrieval top-100 accuracy: 0.998.\n",
            "Ranking RMSE: 0.511.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(cached_test, return_dict=True)"
      ],
      "metadata": {
        "id": "PBjDkzcUjX4E",
        "outputId": "4aeaea19-ffd7-4fdf-fcdf-2c09ec9c46db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 2s 71ms/step - root_mean_squared_error: 0.5108 - factorized_top_k/top_1_categorical_accuracy: 0.5855 - factorized_top_k/top_5_categorical_accuracy: 0.6765 - factorized_top_k/top_10_categorical_accuracy: 0.6852 - factorized_top_k/top_50_categorical_accuracy: 0.8700 - factorized_top_k/top_100_categorical_accuracy: 0.9984 - loss: 1347.4512 - regularization_loss: 0.0000e+00 - total_loss: 1347.4512\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'factorized_top_k/top_100_categorical_accuracy': 0.9983615279197693,\n",
              " 'factorized_top_k/top_10_categorical_accuracy': 0.6852357387542725,\n",
              " 'factorized_top_k/top_1_categorical_accuracy': 0.5854724049568176,\n",
              " 'factorized_top_k/top_50_categorical_accuracy': 0.8700163960456848,\n",
              " 'factorized_top_k/top_5_categorical_accuracy': 0.6764973402023315,\n",
              " 'loss': 557.6878051757812,\n",
              " 'regularization_loss': 0,\n",
              " 'root_mean_squared_error': 0.5108075737953186,\n",
              " 'total_loss': 557.6878051757812}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "model.fit(cached_train, epochs=10)\n",
        "metrics = model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
        "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
      ],
      "metadata": {
        "id": "e4GwNM_k49pB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
        "# recommends movies out of the entire movies dataset.\n",
        "index.index_from_dataset(\n",
        "  tf.data.Dataset.zip((locations.batch(100), locations.batch(100).map(model.location_model)))\n",
        ")\n",
        "# Get recommendations.\n",
        "user_id = \"183\"\n",
        "_, titles = index(tf.constant([user_id]))\n",
        "print(f\"Recommendations for Dimas : {titles[0, :7]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ik9IDPRr8dX",
        "outputId": "d11f3b05-737c-4a76-9d25-255d4f55d9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for Dimas : [b'GUNUNG FUJI' b'WAKATOBI' b'PRANCIS' b'LABUAN BAJO' b'TAWANGMANGU'\n",
            " b'BALI TOWER' b'NUSA TENGGARA BARAT']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Joint model\n",
        "\n",
        "Let's now train a model that assigns positive weights to both tasks."
      ],
      "metadata": {
        "id": "mzsVCjY-ZQy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MovielensModel(rating_weight=1.0, retrieval_weight=1.0)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
      ],
      "metadata": {
        "id": "ss0ZFo-0ZRK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(cached_train, epochs=3)\n",
        "metrics = model.evaluate(cached_test, return_dict=True)\n",
        "\n",
        "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
        "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bCxEhoFZT8o",
        "outputId": "618ac0c8-7807-4167-abf6-678bfba8a5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "43/43 [==============================] - 4s 69ms/step - root_mean_squared_error: 0.4551 - factorized_top_k/top_1_categorical_accuracy: 0.0099 - factorized_top_k/top_5_categorical_accuracy: 0.0650 - factorized_top_k/top_10_categorical_accuracy: 0.1283 - factorized_top_k/top_50_categorical_accuracy: 0.5032 - factorized_top_k/top_100_categorical_accuracy: 0.8166 - loss: 3176.1545 - regularization_loss: 0.0000e+00 - total_loss: 3176.1545\n",
            "Epoch 2/3\n",
            "43/43 [==============================] - 3s 71ms/step - root_mean_squared_error: 0.4460 - factorized_top_k/top_1_categorical_accuracy: 0.0100 - factorized_top_k/top_5_categorical_accuracy: 0.0776 - factorized_top_k/top_10_categorical_accuracy: 0.2163 - factorized_top_k/top_50_categorical_accuracy: 0.6746 - factorized_top_k/top_100_categorical_accuracy: 0.9475 - loss: 3176.1255 - regularization_loss: 0.0000e+00 - total_loss: 3176.1255\n",
            "Epoch 3/3\n",
            "43/43 [==============================] - 3s 69ms/step - root_mean_squared_error: 0.4460 - factorized_top_k/top_1_categorical_accuracy: 0.1427 - factorized_top_k/top_5_categorical_accuracy: 0.2344 - factorized_top_k/top_10_categorical_accuracy: 0.4920 - factorized_top_k/top_50_categorical_accuracy: 0.8597 - factorized_top_k/top_100_categorical_accuracy: 0.9830 - loss: 3175.7151 - regularization_loss: 0.0000e+00 - total_loss: 3175.7151\n",
            "22/22 [==============================] - 2s 61ms/step - root_mean_squared_error: 0.4467 - factorized_top_k/top_1_categorical_accuracy: 0.1503 - factorized_top_k/top_5_categorical_accuracy: 0.2337 - factorized_top_k/top_10_categorical_accuracy: 0.2616 - factorized_top_k/top_50_categorical_accuracy: 0.8386 - factorized_top_k/top_100_categorical_accuracy: 0.9650 - loss: 1344.1808 - regularization_loss: 0.0000e+00 - total_loss: 1344.1808\n",
            "Retrieval top-100 accuracy: 0.965.\n",
            "Ranking RMSE: 0.447.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INTERFACE FOR NEW USER"
      ],
      "metadata": {
        "id": "cDnTAKradwOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "worksheetCat = gc.open('capstone_dataset').worksheet('category')\n",
        "rows = worksheetCat.get_all_values()\n",
        "dfCategories = pd.DataFrame.from_records(rows[1:], columns=rows[0])\n",
        "list_categories = [i for i in dfCategories['category'] if i != '']\n",
        "worksheetUserFeat = gc.open('capstone_dataset').worksheet('userFeatures(coldstartsol)')\n",
        "rows = worksheetUserFeat.get_all_values()\n",
        "dfUserFeat = pd.DataFrame.from_records(rows[1:], columns=rows[0])"
      ],
      "metadata": {
        "id": "jNQ7bLGed0Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_user_id = dfUserFeat['user_id'].to_list()\n",
        "last_user_id = int(last_user_id[-1]) + 1 \n",
        "\n",
        "def input_user_data():\n",
        "  user_data = {}\n",
        "  # input_name = input(\"Nama: \")\n",
        "  user_data['user_id'] = str(last_user_id)\n",
        "  last_user_ids = last_user_id + 1\n",
        "  user_categories = list()\n",
        "  for i in list_categories:\n",
        "    input_category = int(input(\"{} ? (1: yes, 0: no) : \".format(i)))\n",
        "    if input_category == 1:\n",
        "      user_categories.append(i)\n",
        "  user_data[\"categories\"] = user_categories\n",
        "  return user_data, last_user_ids\n",
        "user_data, last_user_id = input_user_data()"
      ],
      "metadata": {
        "id": "rTmPsti6mnNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_dummy_category(location):\n",
        "  if location == \"beach\":\n",
        "    return 121\n",
        "  if location == \"mountain\":\n",
        "    return 123\n",
        "  if location == \"lake\":\n",
        "    return 124\n",
        "  if location == \"zoo\":\n",
        "    return 125\n",
        "  if location == \"river\":\n",
        "    return 126\n",
        "  if location == \"conservation\":\n",
        "    return 127\n",
        "  if location == \"waterpark\":\n",
        "    return 128\n",
        "  if location == \"waterfall\":\n",
        "    return 129\n",
        "  if location == \"artGallery\":\n",
        "    return 130\n",
        "  if location == \"amusementPark\":\n",
        "    return 131\n",
        "  if location == \"mall\":\n",
        "    return 132\n",
        "  if location == \"HistoricalPlace\":\n",
        "    return 133\n",
        "  if location == \"religious\":\n",
        "    return 134\n",
        "  if location == \"outbond\":\n",
        "    return 135\n",
        "  if location == \"culinary\":\n",
        "    return 136\n",
        "  if location == \"photoHunting\":\n",
        "    return 137\n",
        "  if location == \"sightSeeing\":\n",
        "    return 138\n",
        "  if location == \"shopping\":\n",
        "    return 139"
      ],
      "metadata": {
        "id": "gSkVFHcWtpg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_frame(user_data, dfUserFeatcold):\n",
        "  user_id = [user_data['user_id'] for i in list_categories]\n",
        "  like = ['0' for i in list_categories]\n",
        "  categories = list_categories\n",
        "  location = categories\n",
        "  location_id = [encode_dummy_category(i) for i in list_categories]\n",
        "  add = list()\n",
        "  for i in list_categories:\n",
        "    if i in user_data['categories']:\n",
        "      add.append(\"1\")\n",
        "    else:\n",
        "      add.append(\"0\")\n",
        "  data = {'user_id' : user_id, 'like' : like, \"add\" : add, \"category\" : categories, \"location\" : location, \"location_id\" : location_id}\n",
        "  df = pd.DataFrame(data)\n",
        "  df_concat = pd.concat([dfUserFeatcold,df], ignore_index= True)\n",
        "  return df, df_concat   \n"
      ],
      "metadata": {
        "id": "EYFj9hd4qiyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df, df_concat = create_data_frame(user_data, dfUserFeat)\n",
        "worksheetUser = gc.open('capstone_dataset').worksheet('userFeatures')\n",
        "set_with_dataframe(worksheetUser, df_concat)"
      ],
      "metadata": {
        "id": "tfJda93yuN0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}